\subsection{Overview}

A software package contains all the required file to produce an
application or a library.


The content of the tarball is directly the unprocess material used by
software developpers to write software: it has to be processed to be
of use for an end-user. On the opposite, a binary package is of no use
for developpers but contain a directly usable application.


This section will discuss what are the different files present in a
package, how they are processed and where they are copied in the
directory hierarchy.


\begin{description}
\item[source files] are files that can be compiled to produce an
  executable file.
\item[resources] are text or binary files used by an application
  (i.e. images, icons, \ldots).
\item[documentation] can be copied or generated depending on its
  format.
\end{description}


\subsection{Source files}


Many programming languages exist and each has its own building
mechanism, the goal of this paragraph is only giving a general idea
about how the building process is generally working.


Programming languages can be categorized in compiled or interpreted
languages. Compiled languages such as C, C++, Pascal transform source
files (text files containing instructions) into an executable. If the
executable has an entry point, it is a binary which can be runned by
the user, if there is not it is a library. Libraries are designed to
store sets of procedures that will be reused by different
applications.  The other kind of programming languages are interpreted
languages such as Python, Ruby: the end-user has to run an interpreter
on a source file itself to run the program. It is repeated each time
the software is used.
The compiler is a compile-time dependency whether an interpreter is a
run-time dependency.


\begin{figure}[htbp]
\centering
\begin{tikzpicture}[point/.style={coordinate},>=stealth',thick,draw=black!50,
                    tip/.style={->,shorten >=1pt},every join/.style={rounded corners},
                    hv path/.style={to path={-| (\tikztotarget)}},
                    vh path/.style={to path={|- (\tikztotarget)}}]
  \matrix[column sep=4mm] {
    \node (source)   [pkgstate]    {source file};\\
    & \node (compiler) [pkgaction]   {compiler}; &
    \node (binary)   [pkgstate]    {binary or library};\\

    \node (source2)   [pkgstate]    {source file};\\
  };

  { [start chain]
    { [start branch]
      \chainin (source);
      \chainin (compiler) [join=by {vh path,tip}];
    }
    { [start branch]
      \chainin (source2);
      \chainin (compiler) [join=by {vh path,tip}];
    }
      \chainin (compiler);
    \chainin (binary)  [join=by tip];
  }
\end{tikzpicture}
\caption{Compiling workflow}
\label{fig:compiling_workflow}
\end{figure}


\subsection{Resources}

Resources are the set of all files that are just bundled with an
application without having any transformation applied on them. It
gathers multimedia files such as images, video and sounds but also
preference files.

If the majority are just copied, some can also be generated by the
packaging process to match more precisely the host system.


\subsection{Documentation}

Documentation in software have several forms, especially on
\linux. Each application should provide a \texttt{man} (manual) page
which describes the program usage (its goal and the command line
options it accepts). A more structured format are \texttt{info} files
that contain the whole reference manual and is usually much longer.


However these formats are designed to be viewed in console and are
hence quite limited: no images, sounds or video, no special fonts or
complex type setting. Other documentation systems such as \LaTeX or
HTML/XML based formats such as Docbook are more and more used.


All these formats however share one common point: the document is
generated from a source file that describe the document.


The last case is self-documentation of the source code: this kind of
documentation is generated from tools such as Doxygen which analyzes
the source code from a package and generates developper-oriented
documentation.


\subsection{Building mechanisms}

As seen in the previous sections, different kind of processing has to
be done to generate a project. These processes are controled by
\texttt{Makefile} files. The \texttt{Makefile} format defines
generation rules, i.e. its links a particular kind of output with its
input and shell command lines. For instance, one can define what
command lines have to runned to get a binary from source files. It is
also able to detect what has to be regenerated when changes are done
to source files.


However, these rules depends on plenty of parameters. Some of them
depends on the host platform, on the \linux distribution or even the
user setup! This is the reason a \texttt{configure} file is needed:
this tool tunes the \texttt{Makefile} files in order to adapt them to
the host system.

It controls:
\begin{description}
\item[Compiler] What compiler will be used as several compiler exist
  for most of the programming languages.
\item[Directories] Where will the software be installed on the host
  system?
\item[Compilation profile] What flags will be given to the compiler:
  it will determine if debugging support will be included, if the
  application will be optimized, \ldots
\item[Enabling of optional features] What features will be included in
  the final software?
\end{description}

It also realize severy sanitary checks to make sure all dependencies
(tools, libraries\ldots) are present and that versions are newer
enough.